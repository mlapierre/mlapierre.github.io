Problem solving and critical thinking in science, software development, and software testing.

Software testing, especially manual software testing, is sometimes thought of as nothing more than following a script to confirm that the software under test does what it was designed to do. Writing the script might involve taking points from a set of requirements and turning them into instructions. From that perspective, testing might seem like a boring and relatively mindless task. And to be honest, this is the traditional view created by testing as part of the Waterfall method of software development, in large organisations where the division of labour meant that there were some people who did nothing but follow scripts someone else had written, and report bugs that someone else would investigate.

Science, on the other hand, is undeniably interesting and challenging. So it might be suprising to know that I find both engaging and worth spending my time and effort on. Having worked as a software tester, and having studied a scientific field, I've noticed some similarities that help explain why I'm drawn to both persuits despite their seeming lack of similarity.

[Science can be defined as](https://en.oxforddictionaries.com/definition/science):

> "The intellectual and practical activity encompassing the systematic study of the structure and behaviour of the physical and natural world through observation and experiment."

That doesn't seem to describe following testing scripts at all. Even if you swap "the physical and natural world" for "the software under test", and even if you include the task of writing scripts. But if you consider the entire process of software testing you'll see similarities emerge. For one thing, test scripts have to be written based on something, and in today's world of agile software development, than something tends *not* to be requirements handed down from designers, but rather requirements explored, developed, and refined iteratively. Observation and experiment are a big part of that iterative process. This is especially the case when working on existing software that doesn't have good documentation.

The reality of testing is a lot more than the notion of following a script. A more complete [definition of testing](http://www.satisfice.com/blog/archives/856) is that:

> "Testing is the process of evaluating a product by learning about it through exploration and experimentation, which includes to some degree: questioning, study, modeling, observation, inference, etc." 

When defined that way, it's much clearer how testing and science are similar. Questioning, study, modeling, observation, and inference are all core aspects of science and testing.

Another similarity between science and software testing is that neither truly have and end. There is always more for to discover through science, and, at least in practice if not in theory, there is always more to learn about any non-trivial software. So in both cases it's not productive to think of the entire process as having a goal, but it is necessary to define some reasonable milestone as the completion of a project.

Science can be thought of as trying to better understand the world, rather than trying to prove a particular claim. The scientific method involves a process of making hypotheses, and then gathering and analysing data to draw conclusions about whether the hypothesis is supported. It's possible to find evidence that a hypothesis is not valid, but it's not possible to completely certain that a hypothesis is *the* explanation for the data because other explanations might also fit. After carefully analysing the results of several experiments a clearer understanding can begin to emerge. In that way you can think of science as showing what doesn't work until there's a reasonably solid explanation left. It's not about being right, but about being less wrong. Similarly, testing is not about proving that the software is bug free, but about ruling out as many faults as can be identified until what's left is reasonably solid.

 * science (and testing) is about showing what doesn't work until you're left with what does
 * In both cases the point is not to reach the end, because that's impossible, but to get ever closer.
 * A scientific finding doesn't prove that a theory is right - it provides evidence for a particular hypothesis
 * A test that passes doesn't prove that the software works - it provides evidence that a particular sequence of events doesn't reveal any obvious issues.

 